# -*- coding: utf-8 -*-
"""Dicoding_AprilliaNurAzizah_ProyekAkhir.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DaYBpb9eGjCxGLWLQEoEaQMKQnEDI8Wv

###Nama      : Aprillia Nur Azizah 
###Unsername : aprillianuraz
###Email     : aprilliaazizah3@gmail.com
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import zipfile, os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from keras.models import Sequential
# %matplotlib inline
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

zip_ref = zipfile.ZipFile("/content/drive/MyDrive/Dicoding/Dataset/animals.zip", 'r')
zip_ref.extractall("/tmp")
zip_ref.close()

base_dir = '/tmp/animals'

#print total images in cats, dogs, and panda
print('total cats :', len(os.listdir('/tmp/animals/cats')))
print('total dogs:', len(os.listdir('/tmp/animals/dogs')))
print('total panda :', len(os.listdir('/tmp/animals/panda')))

#image augmentation
train_datagen = ImageDataGenerator(
    rotation_range=20,       
    rescale=1./255,
    shear_range=0.15,
    fill_mode="nearest",
    horizontal_flip=True,
    validation_split=0.2) #20% validation data

batch_size=32

#data generator
train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(150, 150),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training') 
validation_generator = train_datagen.flow_from_directory(
    base_dir, 
    target_size=(150, 150),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation')

steps_per_epoch = len(train_generator)/batch_size*10
validation_steps = len(validation_generator)/batch_size*10

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy')>= 0.86 and logs.get('accuracy')> 0.86):#stop the training if val_accuary >= 0.86
      print("\n Accuracy dan Validation Accuracy sudah mencapai > 86% ") 
      self.model.stop_training = True

callbacks = myCallback()

from tensorflow.keras.applications.vgg16 import VGG16

base_model = VGG16(input_shape = (150, 150, 3), 
                  include_top = False, 
                  weights = 'imagenet')

for layer in base_model.layers:
    layer.trainable = False

x = keras.layers.Flatten()(base_model.output)
x = keras.layers.Dense(512, activation='relu')(x)
x = keras.layers.Dropout(0.5)(x)
x = keras.layers.Dense(3, activation='softmax')(x)


model = tf.keras.models.Model(base_model.input, x)
model = Sequential(layers=model.layers)
model.compile(optimizer =  tf.optimizers.Adam(), loss = 'categorical_crossentropy',metrics = ['accuracy'])
model.summary()

history = model.fit(
        train_generator,
        steps_per_epoch = steps_per_epoch,
        epochs = 30,
        validation_data=validation_generator,   
        callbacks=[callbacks])

#Accuracy Plot
accry = history.history['accuracy']
validation_accry = history.history['val_accuracy']
plt.plot(accry, 'g', label='Training accuracy')
plt.plot(validation_accry , 'b', label='validation accuracy')
plt.title('Training and Validation Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.show()

#Loss Plot
loss = history.history['loss']
validation_loss = history.history['val_loss']
plt.plot(loss, 'g', label='Training loss')
plt.plot(validation_loss , 'b', label='validation loss')
plt.title('Training and Validation  Loss')
plt.ylabel('loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

#Convert TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)